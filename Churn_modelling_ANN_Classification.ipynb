{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9df83d3",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightgreen;font-family:newtimeroman;font-size:30px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Churn_modelling_ANN_Classification</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a817d5f",
   "metadata": {},
   "source": [
    "__Churn__ __Prediction__ __Model__ : \n",
    "\n",
    "It’s a predictive model that estimates — at the level of individual customers — the propensity (or susceptibility) they have to leave. For each customer at any given time, it tells us how high the risk is of losing them in the future.\n",
    "\n",
    "Technically, it’s a binary classifier that divides clients into two groups (classes) — those who leave and those who don’t. In addition to assigning them to one of the two groups, it will typically give us the probability with which the client belongs to that group.\n",
    "\n",
    "It is important to note that this is the probability of belonging to the group of clients who leave. Thus, it is the propensity to leave and not the probability of leaving. However, it is possible to estimate the probability through a churn model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030868a",
   "metadata": {},
   "source": [
    "__Business__ __Problem__ : \n",
    "\n",
    "This data set contains details of a bank's customers and the target variable is a binary variable(Exited) reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.\n",
    "The goal here is to predict whether a customer will churn (i.e. exited = 1) using the provided features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa32229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Libraries:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17669957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "data = pd.read_csv(\"C://PYTHON//AI_ML//Deep_Learning//Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba3a6d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightpink;font-family:newtimeroman;font-size:20px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Exploratory Data Analysis</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d48a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2535be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns are totally unproductive so let's remove them\n",
    "data = data.drop([\"RowNumber\",\"CustomerId\",\"Surname\",], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b118cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521f3016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "426a5475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting the meta data info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb85c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bf589_row0_col0, #T_bf589_row0_col1, #T_bf589_row0_col2, #T_bf589_row0_col3, #T_bf589_row0_col4, #T_bf589_row0_col5, #T_bf589_row0_col6, #T_bf589_row0_col7, #T_bf589_row1_col0, #T_bf589_row1_col1, #T_bf589_row1_col2, #T_bf589_row1_col3, #T_bf589_row1_col4, #T_bf589_row1_col5, #T_bf589_row1_col6, #T_bf589_row1_col7, #T_bf589_row2_col0, #T_bf589_row2_col1, #T_bf589_row2_col2, #T_bf589_row2_col3, #T_bf589_row2_col4, #T_bf589_row2_col5, #T_bf589_row2_col6, #T_bf589_row2_col7, #T_bf589_row3_col0, #T_bf589_row3_col1, #T_bf589_row3_col2, #T_bf589_row3_col3, #T_bf589_row3_col4, #T_bf589_row3_col5, #T_bf589_row3_col6, #T_bf589_row3_col7, #T_bf589_row4_col0, #T_bf589_row4_col1, #T_bf589_row4_col2, #T_bf589_row4_col3, #T_bf589_row4_col4, #T_bf589_row4_col5, #T_bf589_row4_col6, #T_bf589_row4_col7, #T_bf589_row5_col0, #T_bf589_row5_col1, #T_bf589_row5_col2, #T_bf589_row5_col3, #T_bf589_row5_col4, #T_bf589_row5_col5, #T_bf589_row5_col6, #T_bf589_row5_col7, #T_bf589_row6_col0, #T_bf589_row6_col1, #T_bf589_row6_col2, #T_bf589_row6_col3, #T_bf589_row6_col4, #T_bf589_row6_col5, #T_bf589_row6_col6, #T_bf589_row6_col7, #T_bf589_row7_col0, #T_bf589_row7_col1, #T_bf589_row7_col2, #T_bf589_row7_col3, #T_bf589_row7_col4, #T_bf589_row7_col5, #T_bf589_row7_col6, #T_bf589_row7_col7, #T_bf589_row8_col0, #T_bf589_row8_col1, #T_bf589_row8_col2, #T_bf589_row8_col3, #T_bf589_row8_col4, #T_bf589_row8_col5, #T_bf589_row8_col6, #T_bf589_row8_col7 {\n",
       "  background-color: cyan;\n",
       "  color: black;\n",
       "  border-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bf589\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf589_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n",
       "      <th id=\"T_bf589_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n",
       "      <th id=\"T_bf589_level0_col2\" class=\"col_heading level0 col2\" >std</th>\n",
       "      <th id=\"T_bf589_level0_col3\" class=\"col_heading level0 col3\" >min</th>\n",
       "      <th id=\"T_bf589_level0_col4\" class=\"col_heading level0 col4\" >25%</th>\n",
       "      <th id=\"T_bf589_level0_col5\" class=\"col_heading level0 col5\" >50%</th>\n",
       "      <th id=\"T_bf589_level0_col6\" class=\"col_heading level0 col6\" >75%</th>\n",
       "      <th id=\"T_bf589_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row0\" class=\"row_heading level0 row0\" >CreditScore</th>\n",
       "      <td id=\"T_bf589_row0_col0\" class=\"data row0 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row0_col1\" class=\"data row0 col1\" >650.528800</td>\n",
       "      <td id=\"T_bf589_row0_col2\" class=\"data row0 col2\" >96.653299</td>\n",
       "      <td id=\"T_bf589_row0_col3\" class=\"data row0 col3\" >350.000000</td>\n",
       "      <td id=\"T_bf589_row0_col4\" class=\"data row0 col4\" >584.000000</td>\n",
       "      <td id=\"T_bf589_row0_col5\" class=\"data row0 col5\" >652.000000</td>\n",
       "      <td id=\"T_bf589_row0_col6\" class=\"data row0 col6\" >718.000000</td>\n",
       "      <td id=\"T_bf589_row0_col7\" class=\"data row0 col7\" >850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row1\" class=\"row_heading level0 row1\" >Age</th>\n",
       "      <td id=\"T_bf589_row1_col0\" class=\"data row1 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row1_col1\" class=\"data row1 col1\" >38.921800</td>\n",
       "      <td id=\"T_bf589_row1_col2\" class=\"data row1 col2\" >10.487806</td>\n",
       "      <td id=\"T_bf589_row1_col3\" class=\"data row1 col3\" >18.000000</td>\n",
       "      <td id=\"T_bf589_row1_col4\" class=\"data row1 col4\" >32.000000</td>\n",
       "      <td id=\"T_bf589_row1_col5\" class=\"data row1 col5\" >37.000000</td>\n",
       "      <td id=\"T_bf589_row1_col6\" class=\"data row1 col6\" >44.000000</td>\n",
       "      <td id=\"T_bf589_row1_col7\" class=\"data row1 col7\" >92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row2\" class=\"row_heading level0 row2\" >Tenure</th>\n",
       "      <td id=\"T_bf589_row2_col0\" class=\"data row2 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row2_col1\" class=\"data row2 col1\" >5.012800</td>\n",
       "      <td id=\"T_bf589_row2_col2\" class=\"data row2 col2\" >2.892174</td>\n",
       "      <td id=\"T_bf589_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row2_col4\" class=\"data row2 col4\" >3.000000</td>\n",
       "      <td id=\"T_bf589_row2_col5\" class=\"data row2 col5\" >5.000000</td>\n",
       "      <td id=\"T_bf589_row2_col6\" class=\"data row2 col6\" >7.000000</td>\n",
       "      <td id=\"T_bf589_row2_col7\" class=\"data row2 col7\" >10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row3\" class=\"row_heading level0 row3\" >Balance</th>\n",
       "      <td id=\"T_bf589_row3_col0\" class=\"data row3 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row3_col1\" class=\"data row3 col1\" >76485.889288</td>\n",
       "      <td id=\"T_bf589_row3_col2\" class=\"data row3 col2\" >62397.405202</td>\n",
       "      <td id=\"T_bf589_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row3_col4\" class=\"data row3 col4\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row3_col5\" class=\"data row3 col5\" >97198.540000</td>\n",
       "      <td id=\"T_bf589_row3_col6\" class=\"data row3 col6\" >127644.240000</td>\n",
       "      <td id=\"T_bf589_row3_col7\" class=\"data row3 col7\" >250898.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row4\" class=\"row_heading level0 row4\" >NumOfProducts</th>\n",
       "      <td id=\"T_bf589_row4_col0\" class=\"data row4 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row4_col1\" class=\"data row4 col1\" >1.530200</td>\n",
       "      <td id=\"T_bf589_row4_col2\" class=\"data row4 col2\" >0.581654</td>\n",
       "      <td id=\"T_bf589_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row4_col5\" class=\"data row4 col5\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row4_col6\" class=\"data row4 col6\" >2.000000</td>\n",
       "      <td id=\"T_bf589_row4_col7\" class=\"data row4 col7\" >4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row5\" class=\"row_heading level0 row5\" >HasCrCard</th>\n",
       "      <td id=\"T_bf589_row5_col0\" class=\"data row5 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row5_col1\" class=\"data row5 col1\" >0.705500</td>\n",
       "      <td id=\"T_bf589_row5_col2\" class=\"data row5 col2\" >0.455840</td>\n",
       "      <td id=\"T_bf589_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row5_col6\" class=\"data row5 col6\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row5_col7\" class=\"data row5 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row6\" class=\"row_heading level0 row6\" >IsActiveMember</th>\n",
       "      <td id=\"T_bf589_row6_col0\" class=\"data row6 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row6_col1\" class=\"data row6 col1\" >0.515100</td>\n",
       "      <td id=\"T_bf589_row6_col2\" class=\"data row6 col2\" >0.499797</td>\n",
       "      <td id=\"T_bf589_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row6_col5\" class=\"data row6 col5\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_bf589_row6_col7\" class=\"data row6 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row7\" class=\"row_heading level0 row7\" >EstimatedSalary</th>\n",
       "      <td id=\"T_bf589_row7_col0\" class=\"data row7 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row7_col1\" class=\"data row7 col1\" >100090.239881</td>\n",
       "      <td id=\"T_bf589_row7_col2\" class=\"data row7 col2\" >57510.492818</td>\n",
       "      <td id=\"T_bf589_row7_col3\" class=\"data row7 col3\" >11.580000</td>\n",
       "      <td id=\"T_bf589_row7_col4\" class=\"data row7 col4\" >51002.110000</td>\n",
       "      <td id=\"T_bf589_row7_col5\" class=\"data row7 col5\" >100193.915000</td>\n",
       "      <td id=\"T_bf589_row7_col6\" class=\"data row7 col6\" >149388.247500</td>\n",
       "      <td id=\"T_bf589_row7_col7\" class=\"data row7 col7\" >199992.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bf589_level0_row8\" class=\"row_heading level0 row8\" >Exited</th>\n",
       "      <td id=\"T_bf589_row8_col0\" class=\"data row8 col0\" >10000.000000</td>\n",
       "      <td id=\"T_bf589_row8_col1\" class=\"data row8 col1\" >0.203700</td>\n",
       "      <td id=\"T_bf589_row8_col2\" class=\"data row8 col2\" >0.402769</td>\n",
       "      <td id=\"T_bf589_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row8_col6\" class=\"data row8 col6\" >0.000000</td>\n",
       "      <td id=\"T_bf589_row8_col7\" class=\"data row8 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1861feceda0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting stats about dataset\n",
    "data.describe().T.style.set_properties(**{'background-color': 'cyan','color': 'black','border-color': 'red'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ddd47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382628b6",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightpink;font-family:newtimeroman;font-size:20px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Data Visualisation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cc4130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's See How The Target feature is:\n",
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f7fa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=data['Exited'], palette=['mediumspringgreen','olive'])\n",
    "plt.subplot(1,2,2)\n",
    "data['Exited'].value_counts().plot(kind='pie', autopct='%.2f%%', explode=[0,0.1], startangle=360, colors=['mediumspringgreen','olive'],labels = ['No Churn','Churn',])\n",
    "plt.suptitle('CUSTOMER CHURN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df2978",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "\n",
    "We’re trying to predict users that left the bank in the previous month. It’s a binary classification problem with an unbalanced target.\n",
    "\n",
    "    Churn:0 = No – 79.63%\n",
    "    Churn:1 = Yes – 20.37%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24faf175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">France</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.203450</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.127134</td>\n",
       "      <td>2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Germany</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.375524</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.278116</td>\n",
       "      <td>1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Spain</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.131124</td>\n",
       "      <td>1388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Exited      \n",
       "                      mean count\n",
       "Geography Gender                \n",
       "France    Female  0.203450  2261\n",
       "          Male    0.127134  2753\n",
       "Germany   Female  0.375524  1193\n",
       "          Male    0.278116  1316\n",
       "Spain     Female  0.212121  1089\n",
       "          Male    0.131124  1388"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s check how “Gender” and “Geography” are related to customer churn.\n",
    "data[['Geography','Gender','Exited']].groupby(['Geography','Gender']).agg(['mean','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f10687",
   "metadata": {},
   "source": [
    "__Observation:__\n",
    "    \n",
    "- From  the above information Female Exited rate is higher than males in three countries and the country germany is in frist palce with high churn rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b0f0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure   Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2      0.00              1   \n",
       "1          608     Spain  Female   41       1  83807.86              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f264b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(data[\"Age\"], color = \"red\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data[\"Age\"], color = \"green\")\n",
    "plt.suptitle(\"Checking for Distribution and Outliers for Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33bfa722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,3))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(data[\"Balance\"], color = \"red\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data[\"Balance\"], color = \"green\")\n",
    "plt.title(\"Checking for Distribution and Outliers for Balance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd4762e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,3))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(data[\"EstimatedSalary\"], color = \"red\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data[\"EstimatedSalary\"], color = \"green\")\n",
    "plt.title(\"Checking for Distribution and Outliers for EstimatedSalary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c9155",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightpink;font-family:newtimeroman;font-size:20px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Feature Engineering</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa7a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding of Categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b63266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ef1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_data = ohe.fit_transform(data[['Geography','Gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2911458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1.],\n",
       "       [1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b92cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geography_France', 'Geography_Germany', 'Geography_Spain',\n",
       "       'Gender_Female', 'Gender_Male'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ohe.get_feature_names_out()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f065155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "0                  1.0                0.0              0.0            1.0   \n",
       "1                  0.0                0.0              1.0            1.0   \n",
       "2                  1.0                0.0              0.0            1.0   \n",
       "3                  1.0                0.0              0.0            1.0   \n",
       "4                  0.0                0.0              1.0            1.0   \n",
       "...                ...                ...              ...            ...   \n",
       "9995               1.0                0.0              0.0            0.0   \n",
       "9996               1.0                0.0              0.0            0.0   \n",
       "9997               1.0                0.0              0.0            1.0   \n",
       "9998               0.0                1.0              0.0            0.0   \n",
       "9999               1.0                0.0              0.0            1.0   \n",
       "\n",
       "      Gender_Male  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "...           ...  \n",
       "9995          1.0  \n",
       "9996          1.0  \n",
       "9997          0.0  \n",
       "9998          1.0  \n",
       "9999          0.0  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohenew = pd.DataFrame(ohe_data, columns = cols)\n",
    "ohenew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06fd061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop([\"Geography\",\"Gender\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fc49ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  \n",
       "0                  1        101348.88       1  \n",
       "1                  1        112542.58       0  \n",
       "2                  0        113931.57       1  \n",
       "3                  0         93826.63       0  \n",
       "4                  1         79084.10       0  \n",
       "...              ...              ...     ...  \n",
       "9995               0         96270.64       0  \n",
       "9996               1        101699.77       0  \n",
       "9997               1         42085.58       1  \n",
       "9998               0         92888.52       1  \n",
       "9999               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f2266c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "0                  1.0                0.0              0.0            1.0   \n",
       "1                  0.0                0.0              1.0            1.0   \n",
       "2                  1.0                0.0              0.0            1.0   \n",
       "3                  1.0                0.0              0.0            1.0   \n",
       "4                  0.0                0.0              1.0            1.0   \n",
       "...                ...                ...              ...            ...   \n",
       "9995               1.0                0.0              0.0            0.0   \n",
       "9996               1.0                0.0              0.0            0.0   \n",
       "9997               1.0                0.0              0.0            1.0   \n",
       "9998               0.0                1.0              0.0            0.0   \n",
       "9999               1.0                0.0              0.0            1.0   \n",
       "\n",
       "      Gender_Male  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             0.0          619   42       2       0.00              1   \n",
       "1             0.0          608   41       1   83807.86              1   \n",
       "2             0.0          502   42       8  159660.80              3   \n",
       "3             0.0          699   39       1       0.00              2   \n",
       "4             0.0          850   43       2  125510.82              1   \n",
       "...           ...          ...  ...     ...        ...            ...   \n",
       "9995          1.0          771   39       5       0.00              2   \n",
       "9996          1.0          516   35      10   57369.61              1   \n",
       "9997          0.0          709   36       7       0.00              1   \n",
       "9998          1.0          772   42       3   75075.31              2   \n",
       "9999          0.0          792   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([ohenew,data1], axis=1)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "776cfad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1dd098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64488ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "694db582",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_data.drop([\"Exited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8e833ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_data[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c476f273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain  Gender_Female  \\\n",
       "0                  1.0                0.0              0.0            1.0   \n",
       "1                  0.0                0.0              1.0            1.0   \n",
       "2                  1.0                0.0              0.0            1.0   \n",
       "3                  1.0                0.0              0.0            1.0   \n",
       "4                  0.0                0.0              1.0            1.0   \n",
       "...                ...                ...              ...            ...   \n",
       "9995               1.0                0.0              0.0            0.0   \n",
       "9996               1.0                0.0              0.0            0.0   \n",
       "9997               1.0                0.0              0.0            1.0   \n",
       "9998               0.0                1.0              0.0            0.0   \n",
       "9999               1.0                0.0              0.0            1.0   \n",
       "\n",
       "      Gender_Male  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             0.0          619   42       2       0.00              1   \n",
       "1             0.0          608   41       1   83807.86              1   \n",
       "2             0.0          502   42       8  159660.80              3   \n",
       "3             0.0          699   39       1       0.00              2   \n",
       "4             0.0          850   43       2  125510.82              1   \n",
       "...           ...          ...  ...     ...        ...            ...   \n",
       "9995          1.0          771   39       5       0.00              2   \n",
       "9996          1.0          516   35      10   57369.61              1   \n",
       "9997          0.0          709   36       7       0.00              1   \n",
       "9998          1.0          772   42       3   75075.31              2   \n",
       "9999          0.0          792   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59ee7c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bda0cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y =  smt.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b50a8a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15926, 13), (15926,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a77233",
   "metadata": {},
   "source": [
    "___TRAIN_TEST_SPLIT___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a25265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac43f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=41,shuffle = True,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdf6c32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11148, 13), (4778, 13), (11148,), (4778,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b88a7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightpink;font-family:newtimeroman;font-size:20px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Model Building</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b32513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.normalization import layer_normalization\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce9a97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(units = 13, kernel_initializer = \"random_uniform\", activation = \"relu\", input_dim = x_train.shape[1]))\n",
    "ann.add(Dense(units = 7, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "ann.add(Dense(units = 4, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "ann.add(Dense(units = 2, kernel_initializer = \"random_uniform\", activation = \"relu\"))\n",
    "ann.add(Dense(units = 1, kernel_initializer = \"random_uniform\", activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10626c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(loss = ['binary_crossentropy'], optimizer = \"adam\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52d040f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 13)                182       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 98        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 325\n",
      "Trainable params: 325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92db36ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6929 - val_accuracy: 0.5416\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5243 - val_loss: 0.6901 - val_accuracy: 0.5733\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5679 - val_loss: 0.6882 - val_accuracy: 0.5726\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5698 - val_loss: 0.6877 - val_accuracy: 0.5726\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.5693 - val_loss: 0.6873 - val_accuracy: 0.5728\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.5693 - val_loss: 0.6863 - val_accuracy: 0.5722\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5696 - val_loss: 0.6859 - val_accuracy: 0.5716\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.5683 - val_loss: 0.6855 - val_accuracy: 0.5716\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.5681 - val_loss: 0.6850 - val_accuracy: 0.5722\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5684 - val_loss: 0.6846 - val_accuracy: 0.5718\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.5693 - val_loss: 0.6850 - val_accuracy: 0.5737\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5686 - val_loss: 0.6852 - val_accuracy: 0.5722\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.5674 - val_loss: 0.6838 - val_accuracy: 0.5714\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5674 - val_loss: 0.6835 - val_accuracy: 0.5724\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5683 - val_loss: 0.6834 - val_accuracy: 0.5707\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5679 - val_loss: 0.6831 - val_accuracy: 0.5714\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5682 - val_loss: 0.6830 - val_accuracy: 0.5728\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.5684 - val_loss: 0.6827 - val_accuracy: 0.5710\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5682 - val_loss: 0.6829 - val_accuracy: 0.5728\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5701 - val_loss: 0.6830 - val_accuracy: 0.5735\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5687 - val_loss: 0.6827 - val_accuracy: 0.5735\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5679 - val_loss: 0.6825 - val_accuracy: 0.5724\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5693 - val_loss: 0.6828 - val_accuracy: 0.5733\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5707 - val_loss: 0.6822 - val_accuracy: 0.5726\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.5701 - val_loss: 0.6821 - val_accuracy: 0.5741\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5680 - val_loss: 0.6822 - val_accuracy: 0.5726\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5689 - val_loss: 0.6821 - val_accuracy: 0.5735\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5704 - val_loss: 0.6818 - val_accuracy: 0.5720\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.5685 - val_loss: 0.6817 - val_accuracy: 0.5745\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5690 - val_loss: 0.6819 - val_accuracy: 0.5745\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5718 - val_loss: 0.6828 - val_accuracy: 0.5728\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5685 - val_loss: 0.6815 - val_accuracy: 0.5726\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5700 - val_loss: 0.6816 - val_accuracy: 0.5718\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5703 - val_loss: 0.6836 - val_accuracy: 0.5747\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.5689 - val_loss: 0.6814 - val_accuracy: 0.5726\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5683 - val_loss: 0.6816 - val_accuracy: 0.5733\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5701 - val_loss: 0.6818 - val_accuracy: 0.5735\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5690 - val_loss: 0.6816 - val_accuracy: 0.5720\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5701 - val_loss: 0.6820 - val_accuracy: 0.5726\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5726 - val_loss: 0.6814 - val_accuracy: 0.5743\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5698 - val_loss: 0.6813 - val_accuracy: 0.5735\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5696 - val_loss: 0.6812 - val_accuracy: 0.5741\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5726 - val_loss: 0.6816 - val_accuracy: 0.5735\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5719 - val_loss: 0.6813 - val_accuracy: 0.5728\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6839 - accuracy: 0.5649 - val_loss: 0.6814 - val_accuracy: 0.5733\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5728 - val_loss: 0.6814 - val_accuracy: 0.5770\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.5733 - val_loss: 0.6823 - val_accuracy: 0.5772\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5745 - val_loss: 0.6824 - val_accuracy: 0.5735\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5704 - val_loss: 0.6811 - val_accuracy: 0.5747\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5718 - val_loss: 0.6811 - val_accuracy: 0.5733\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5723 - val_loss: 0.6816 - val_accuracy: 0.5787\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5701 - val_loss: 0.6811 - val_accuracy: 0.5737\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5716 - val_loss: 0.6818 - val_accuracy: 0.5793\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5725 - val_loss: 0.6812 - val_accuracy: 0.5753\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5727 - val_loss: 0.6815 - val_accuracy: 0.5747\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5713 - val_loss: 0.6812 - val_accuracy: 0.5718\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5736 - val_loss: 0.6817 - val_accuracy: 0.5745\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5719 - val_loss: 0.6820 - val_accuracy: 0.5745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5728 - val_loss: 0.6814 - val_accuracy: 0.5804\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5717 - val_loss: 0.6809 - val_accuracy: 0.5735\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5716 - val_loss: 0.6810 - val_accuracy: 0.5726\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5712 - val_loss: 0.6813 - val_accuracy: 0.5726\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5729 - val_loss: 0.6812 - val_accuracy: 0.5747\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5712 - val_loss: 0.6812 - val_accuracy: 0.5747\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5715 - val_loss: 0.6812 - val_accuracy: 0.5751\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5738 - val_loss: 0.6810 - val_accuracy: 0.5724\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5718 - val_loss: 0.6817 - val_accuracy: 0.5768\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.5721 - val_loss: 0.6813 - val_accuracy: 0.5776\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5716 - val_loss: 0.6816 - val_accuracy: 0.5745\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5737 - val_loss: 0.6810 - val_accuracy: 0.5741\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5729 - val_loss: 0.6810 - val_accuracy: 0.5733\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5712 - val_loss: 0.6817 - val_accuracy: 0.5827\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5725 - val_loss: 0.6817 - val_accuracy: 0.5789\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5717 - val_loss: 0.6810 - val_accuracy: 0.5745\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5740 - val_loss: 0.6825 - val_accuracy: 0.5756\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.5749 - val_loss: 0.6810 - val_accuracy: 0.5733\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5709 - val_loss: 0.6809 - val_accuracy: 0.5728\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5732 - val_loss: 0.6814 - val_accuracy: 0.5753\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5717 - val_loss: 0.6810 - val_accuracy: 0.5741\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5733 - val_loss: 0.6809 - val_accuracy: 0.5735\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5742 - val_loss: 0.6810 - val_accuracy: 0.5733\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5741 - val_loss: 0.6814 - val_accuracy: 0.5747\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5730 - val_loss: 0.6809 - val_accuracy: 0.5737\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5723 - val_loss: 0.6810 - val_accuracy: 0.5741\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5714 - val_loss: 0.6810 - val_accuracy: 0.5747\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5745 - val_loss: 0.6814 - val_accuracy: 0.5751\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5715 - val_loss: 0.6810 - val_accuracy: 0.5745\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5727 - val_loss: 0.6810 - val_accuracy: 0.5762\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5740 - val_loss: 0.6813 - val_accuracy: 0.5795\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5736 - val_loss: 0.6810 - val_accuracy: 0.5728\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5719 - val_loss: 0.6811 - val_accuracy: 0.5739\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5732 - val_loss: 0.6809 - val_accuracy: 0.5733\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5719 - val_loss: 0.6810 - val_accuracy: 0.5728\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6810 - accuracy: 0.5723 - val_loss: 0.6808 - val_accuracy: 0.5743\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5734 - val_loss: 0.6808 - val_accuracy: 0.5739\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5721 - val_loss: 0.6808 - val_accuracy: 0.5781\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5737 - val_loss: 0.6815 - val_accuracy: 0.5776\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5738 - val_loss: 0.6809 - val_accuracy: 0.5726\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5722 - val_loss: 0.6815 - val_accuracy: 0.5753\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5734 - val_loss: 0.6823 - val_accuracy: 0.5753\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5734 - val_loss: 0.6808 - val_accuracy: 0.5745\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5731 - val_loss: 0.6816 - val_accuracy: 0.5774\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5743 - val_loss: 0.6813 - val_accuracy: 0.5745\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5749 - val_loss: 0.6828 - val_accuracy: 0.5747\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5733 - val_loss: 0.6814 - val_accuracy: 0.5753\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5731 - val_loss: 0.6810 - val_accuracy: 0.5733\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5734 - val_loss: 0.6811 - val_accuracy: 0.5756\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5719 - val_loss: 0.6809 - val_accuracy: 0.5728\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5728 - val_loss: 0.6808 - val_accuracy: 0.5747\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5732 - val_loss: 0.6809 - val_accuracy: 0.5749\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5737 - val_loss: 0.6808 - val_accuracy: 0.5743\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5727 - val_loss: 0.6803 - val_accuracy: 0.5818\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5766 - val_loss: 0.6808 - val_accuracy: 0.5733\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5726 - val_loss: 0.6811 - val_accuracy: 0.5799\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5745 - val_loss: 0.6807 - val_accuracy: 0.5745\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.5735 - val_loss: 0.6813 - val_accuracy: 0.5795\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.5739 - val_loss: 0.6806 - val_accuracy: 0.5760\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5736 - val_loss: 0.6807 - val_accuracy: 0.5728\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5739 - val_loss: 0.6809 - val_accuracy: 0.5737\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5728 - val_loss: 0.6807 - val_accuracy: 0.5745\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5747 - val_loss: 0.6812 - val_accuracy: 0.5772\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5758 - val_loss: 0.6812 - val_accuracy: 0.5774\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5730 - val_loss: 0.6811 - val_accuracy: 0.5799\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5734 - val_loss: 0.6812 - val_accuracy: 0.5760\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.5735 - val_loss: 0.6808 - val_accuracy: 0.5749\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.5730 - val_loss: 0.6808 - val_accuracy: 0.5733\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5752 - val_loss: 0.6810 - val_accuracy: 0.5793\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5731 - val_loss: 0.6811 - val_accuracy: 0.5781\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5749 - val_loss: 0.6810 - val_accuracy: 0.5787\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5726 - val_loss: 0.6806 - val_accuracy: 0.5762\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5738 - val_loss: 0.6810 - val_accuracy: 0.5770\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5732 - val_loss: 0.6806 - val_accuracy: 0.5747\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5730 - val_loss: 0.6810 - val_accuracy: 0.5808\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.5743 - val_loss: 0.6808 - val_accuracy: 0.5756\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5738 - val_loss: 0.6810 - val_accuracy: 0.5762\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5745 - val_loss: 0.6810 - val_accuracy: 0.5785\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5753 - val_loss: 0.6806 - val_accuracy: 0.5737\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5745 - val_loss: 0.6806 - val_accuracy: 0.5756\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5729 - val_loss: 0.6805 - val_accuracy: 0.5776\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5756 - val_loss: 0.6803 - val_accuracy: 0.5779\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5687 - val_loss: 0.6808 - val_accuracy: 0.5758\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5745 - val_loss: 0.6808 - val_accuracy: 0.5785\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5739 - val_loss: 0.6800 - val_accuracy: 0.5762\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5728 - val_loss: 0.6811 - val_accuracy: 0.5766\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5721 - val_loss: 0.6803 - val_accuracy: 0.5739\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5747 - val_loss: 0.6801 - val_accuracy: 0.5745\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5773 - val_loss: 0.6799 - val_accuracy: 0.5768\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5753 - val_loss: 0.6800 - val_accuracy: 0.5753\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.5753 - val_loss: 0.6804 - val_accuracy: 0.5781\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5749 - val_loss: 0.6807 - val_accuracy: 0.5806\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5774 - val_loss: 0.6800 - val_accuracy: 0.5753\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5760 - val_loss: 0.6807 - val_accuracy: 0.5770\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5759 - val_loss: 0.6806 - val_accuracy: 0.5776\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.5723 - val_loss: 0.6805 - val_accuracy: 0.5768\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5747 - val_loss: 0.6803 - val_accuracy: 0.5749\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5740 - val_loss: 0.6801 - val_accuracy: 0.5756\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5762 - val_loss: 0.6801 - val_accuracy: 0.5781\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5745 - val_loss: 0.6818 - val_accuracy: 0.5772\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.5755 - val_loss: 0.6797 - val_accuracy: 0.5745\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5741 - val_loss: 0.6802 - val_accuracy: 0.5783\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5757 - val_loss: 0.6801 - val_accuracy: 0.5762\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5763 - val_loss: 0.6800 - val_accuracy: 0.5753\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5762 - val_loss: 0.6798 - val_accuracy: 0.5770\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5757 - val_loss: 0.6798 - val_accuracy: 0.5747\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5744 - val_loss: 0.6798 - val_accuracy: 0.5797\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5768 - val_loss: 0.6802 - val_accuracy: 0.5797\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5730 - val_loss: 0.6800 - val_accuracy: 0.5745\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5745 - val_loss: 0.6797 - val_accuracy: 0.5762\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5753 - val_loss: 0.6801 - val_accuracy: 0.5776\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5753 - val_loss: 0.6792 - val_accuracy: 0.5781\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5755 - val_loss: 0.6799 - val_accuracy: 0.5776\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.5771 - val_loss: 0.6800 - val_accuracy: 0.5739\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5741 - val_loss: 0.6800 - val_accuracy: 0.5768\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5750 - val_loss: 0.6800 - val_accuracy: 0.5776\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6799 - accuracy: 0.5761 - val_loss: 0.6798 - val_accuracy: 0.5802\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5718 - val_loss: 0.6813 - val_accuracy: 0.5818\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.5701 - val_loss: 0.6802 - val_accuracy: 0.5758\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5759 - val_loss: 0.6800 - val_accuracy: 0.5749\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.5771 - val_loss: 0.6802 - val_accuracy: 0.5756\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5773 - val_loss: 0.6800 - val_accuracy: 0.5753\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5766 - val_loss: 0.6798 - val_accuracy: 0.5787\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.5793 - val_loss: 0.6817 - val_accuracy: 0.5776\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.5731 - val_loss: 0.6802 - val_accuracy: 0.5764\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.5727 - val_loss: 0.6803 - val_accuracy: 0.5766\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5751 - val_loss: 0.6807 - val_accuracy: 0.5779\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5753 - val_loss: 0.6818 - val_accuracy: 0.5762\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.5730 - val_loss: 0.6797 - val_accuracy: 0.5766\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5756 - val_loss: 0.6801 - val_accuracy: 0.5804\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5759 - val_loss: 0.6799 - val_accuracy: 0.5772\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5764 - val_loss: 0.6796 - val_accuracy: 0.5772\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5745 - val_loss: 0.6795 - val_accuracy: 0.5747\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.5762 - val_loss: 0.6795 - val_accuracy: 0.5779\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.5775 - val_loss: 0.6794 - val_accuracy: 0.5768\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5767 - val_loss: 0.6794 - val_accuracy: 0.5779\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6789 - accuracy: 0.5764 - val_loss: 0.6792 - val_accuracy: 0.5770\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.5775 - val_loss: 0.6795 - val_accuracy: 0.5810\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5771 - val_loss: 0.6797 - val_accuracy: 0.5791\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5797 - val_loss: 0.6799 - val_accuracy: 0.5779\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5761 - val_loss: 0.6785 - val_accuracy: 0.5776\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5769 - val_loss: 0.6780 - val_accuracy: 0.5808\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5770 - val_loss: 0.6773 - val_accuracy: 0.5810\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5786 - val_loss: 0.6786 - val_accuracy: 0.5816\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5811 - val_loss: 0.6777 - val_accuracy: 0.5810\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5773 - val_loss: 0.6808 - val_accuracy: 0.5724\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5806 - val_loss: 0.6795 - val_accuracy: 0.5869\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5750 - val_loss: 0.6786 - val_accuracy: 0.5760\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5750 - val_loss: 0.6793 - val_accuracy: 0.5866\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5788 - val_loss: 0.6791 - val_accuracy: 0.5785\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.5807 - val_loss: 0.6786 - val_accuracy: 0.5898\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5798 - val_loss: 0.6784 - val_accuracy: 0.5856\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.5812 - val_loss: 0.6783 - val_accuracy: 0.5783\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.5837 - val_loss: 0.6771 - val_accuracy: 0.5764\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5792 - val_loss: 0.6766 - val_accuracy: 0.5839\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5804 - val_loss: 0.6800 - val_accuracy: 0.5785\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5853 - val_loss: 0.6786 - val_accuracy: 0.5776\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6811 - accuracy: 0.5788 - val_loss: 0.6776 - val_accuracy: 0.5898\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5821 - val_loss: 0.6764 - val_accuracy: 0.5816\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.5849 - val_loss: 0.6754 - val_accuracy: 0.5892\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5918 - val_loss: 0.6745 - val_accuracy: 0.5959\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.5875 - val_loss: 0.6737 - val_accuracy: 0.6086\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5968 - val_loss: 0.6716 - val_accuracy: 0.6051\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5910 - val_loss: 0.6710 - val_accuracy: 0.5892\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5923 - val_loss: 0.6903 - val_accuracy: 0.5741\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5873 - val_loss: 0.6765 - val_accuracy: 0.5808\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5939 - val_loss: 0.6799 - val_accuracy: 0.5563\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.5838 - val_loss: 0.6740 - val_accuracy: 0.5896\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.5872 - val_loss: 0.6740 - val_accuracy: 0.6124\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.5966 - val_loss: 0.6752 - val_accuracy: 0.5827\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.5985 - val_loss: 0.6693 - val_accuracy: 0.6009\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.6057 - val_loss: 0.6678 - val_accuracy: 0.6099\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6090 - val_loss: 0.6647 - val_accuracy: 0.6291\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6147 - val_loss: 0.6640 - val_accuracy: 0.6214\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6228 - val_loss: 0.6646 - val_accuracy: 0.6082\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6302 - val_loss: 0.6544 - val_accuracy: 0.6624\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6063 - val_loss: 0.6589 - val_accuracy: 0.6379\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6102 - val_loss: 0.6644 - val_accuracy: 0.6249\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6178 - val_loss: 0.6671 - val_accuracy: 0.6032\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6198 - val_loss: 0.6624 - val_accuracy: 0.6419\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6286 - val_loss: 0.6679 - val_accuracy: 0.6139\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6236 - val_loss: 0.6620 - val_accuracy: 0.6061\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6366 - val_loss: 0.6757 - val_accuracy: 0.5779\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6285 - val_loss: 0.6513 - val_accuracy: 0.6377\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6527 - val_loss: 0.6480 - val_accuracy: 0.6463\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6671 - accuracy: 0.6023 - val_loss: 0.6673 - val_accuracy: 0.6074\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6404 - val_loss: 0.6520 - val_accuracy: 0.6668\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6471 - val_loss: 0.6464 - val_accuracy: 0.6656\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6752\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6593 - val_loss: 0.6415 - val_accuracy: 0.6741\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6316 - val_loss: 0.6428 - val_accuracy: 0.6722\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6618 - val_loss: 0.6494 - val_accuracy: 0.6626\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6519 - val_loss: 0.6747 - val_accuracy: 0.6082\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6345 - val_loss: 0.6430 - val_accuracy: 0.6777\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6241 - val_loss: 0.6486 - val_accuracy: 0.6551\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6608 - val_loss: 0.6407 - val_accuracy: 0.6699\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6682 - val_loss: 0.6619 - val_accuracy: 0.6304\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6636 - val_loss: 0.6450 - val_accuracy: 0.6624\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6691 - val_loss: 0.6449 - val_accuracy: 0.6733\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6670 - val_loss: 0.6480 - val_accuracy: 0.6576\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6323 - val_loss: 0.6556 - val_accuracy: 0.6254\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.6542 - val_loss: 0.6374 - val_accuracy: 0.6785\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6725 - val_loss: 0.6773 - val_accuracy: 0.6090\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6607 - val_loss: 0.6345 - val_accuracy: 0.6764\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6715 - val_loss: 0.6362 - val_accuracy: 0.6798\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6695 - val_loss: 0.6380 - val_accuracy: 0.6672\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6629 - val_loss: 0.6374 - val_accuracy: 0.6670\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6680 - val_loss: 0.6418 - val_accuracy: 0.6578\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6390 - val_loss: 0.6628 - val_accuracy: 0.6289\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6356 - val_loss: 0.6387 - val_accuracy: 0.6817\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6692 - val_loss: 0.6625 - val_accuracy: 0.6189\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6618 - val_loss: 0.6566 - val_accuracy: 0.6233\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6232 - val_loss: 0.6576 - val_accuracy: 0.6149\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6640 - val_loss: 0.6321 - val_accuracy: 0.6769\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6702 - val_loss: 0.6308 - val_accuracy: 0.6769\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6727 - val_loss: 0.6485 - val_accuracy: 0.6419\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6482 - val_loss: 0.6520 - val_accuracy: 0.6333\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6461 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6722 - val_loss: 0.6334 - val_accuracy: 0.6635\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6737 - val_loss: 0.6277 - val_accuracy: 0.6725\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6764 - val_loss: 0.6671 - val_accuracy: 0.6166\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6416 - val_loss: 0.6414 - val_accuracy: 0.6461\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6737 - val_loss: 0.6283 - val_accuracy: 0.6722\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6705 - val_loss: 0.6415 - val_accuracy: 0.6486\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6684 - val_loss: 0.6380 - val_accuracy: 0.6547\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6738 - val_loss: 0.6267 - val_accuracy: 0.6756\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6643 - val_loss: 0.6342 - val_accuracy: 0.6637\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6447 - val_loss: 0.6308 - val_accuracy: 0.6785\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6735 - val_loss: 0.6275 - val_accuracy: 0.6683\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6809 - val_loss: 0.6665 - val_accuracy: 0.6243\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6521 - val_loss: 0.6227 - val_accuracy: 0.6760\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.6773 - val_loss: 0.6556 - val_accuracy: 0.6321\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6450 - val_loss: 0.6762 - val_accuracy: 0.6030\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6636 - val_loss: 0.6194 - val_accuracy: 0.6796\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6605 - val_loss: 0.6217 - val_accuracy: 0.6779\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6635 - val_loss: 0.6191 - val_accuracy: 0.6766\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6851 - val_loss: 0.6176 - val_accuracy: 0.6806\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6731 - val_loss: 0.6532 - val_accuracy: 0.6321\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6666 - val_loss: 0.6189 - val_accuracy: 0.6764\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6834 - val_loss: 0.6239 - val_accuracy: 0.6741\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6760 - val_loss: 0.6210 - val_accuracy: 0.6792\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6790 - val_loss: 0.6173 - val_accuracy: 0.6823\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.6559 - val_loss: 0.6306 - val_accuracy: 0.6597\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6686 - val_loss: 0.6284 - val_accuracy: 0.6630\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.6770 - val_loss: 0.6147 - val_accuracy: 0.6831\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6837 - val_loss: 0.6180 - val_accuracy: 0.6792\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6691 - val_loss: 0.6277 - val_accuracy: 0.6660\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6790 - val_loss: 0.6145 - val_accuracy: 0.6789\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6729 - val_loss: 0.6292 - val_accuracy: 0.6672\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6580 - val_loss: 0.6141 - val_accuracy: 0.6831\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6796 - val_loss: 0.6133 - val_accuracy: 0.6838\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6838 - val_loss: 0.6256 - val_accuracy: 0.6702\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6761 - val_loss: 0.6119 - val_accuracy: 0.6833\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6807 - val_loss: 0.6203 - val_accuracy: 0.6735\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6773 - val_loss: 0.6172 - val_accuracy: 0.6815\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6802 - val_loss: 0.6433 - val_accuracy: 0.6465\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.6747 - val_loss: 0.6138 - val_accuracy: 0.6785\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.6825 - val_loss: 0.6144 - val_accuracy: 0.6789\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6846 - val_loss: 0.6125 - val_accuracy: 0.6819\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.6747 - val_loss: 0.6119 - val_accuracy: 0.6804\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6782 - val_loss: 0.6156 - val_accuracy: 0.6785\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6702 - val_loss: 0.6181 - val_accuracy: 0.6739\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.6812 - val_loss: 0.6196 - val_accuracy: 0.6781\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6790 - val_loss: 0.6094 - val_accuracy: 0.6867\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6800 - val_loss: 0.6145 - val_accuracy: 0.6785\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6803 - val_loss: 0.6157 - val_accuracy: 0.6796\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.6834 - val_loss: 0.6243 - val_accuracy: 0.6714\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6822 - val_loss: 0.6329 - val_accuracy: 0.6582\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6822 - val_loss: 0.6127 - val_accuracy: 0.6854\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6768 - val_loss: 0.6292 - val_accuracy: 0.6616\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6784 - val_loss: 0.6106 - val_accuracy: 0.6863\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6804 - val_loss: 0.6443 - val_accuracy: 0.6444\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6731 - val_loss: 0.6114 - val_accuracy: 0.6835\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6858 - val_loss: 0.6094 - val_accuracy: 0.6890\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6800 - val_loss: 0.6721 - val_accuracy: 0.6134\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6641 - val_loss: 0.6200 - val_accuracy: 0.6674\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6439 - val_loss: 0.6188 - val_accuracy: 0.6712\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6961 - val_loss: 0.5818 - val_accuracy: 0.7122\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7104 - val_loss: 0.6248 - val_accuracy: 0.6722\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6831 - val_loss: 0.5855 - val_accuracy: 0.7062\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7102 - val_loss: 0.5829 - val_accuracy: 0.7103\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7195 - val_loss: 0.5786 - val_accuracy: 0.7120\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7033 - val_loss: 0.5869 - val_accuracy: 0.7047\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7102 - val_loss: 0.5775 - val_accuracy: 0.7198\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7183 - val_loss: 0.6173 - val_accuracy: 0.6718\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7012 - val_loss: 0.5837 - val_accuracy: 0.7112\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7186 - val_loss: 0.5771 - val_accuracy: 0.7135\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7189 - val_loss: 0.5760 - val_accuracy: 0.7189\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7193 - val_loss: 0.5855 - val_accuracy: 0.7070\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7068 - val_loss: 0.6007 - val_accuracy: 0.6984\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6888 - val_loss: 0.6179 - val_accuracy: 0.6756\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7098 - val_loss: 0.6223 - val_accuracy: 0.6748\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7095 - val_loss: 0.5746 - val_accuracy: 0.7208\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7139 - val_loss: 0.5884 - val_accuracy: 0.7039\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7182 - val_loss: 0.5799 - val_accuracy: 0.7129\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7195 - val_loss: 0.5740 - val_accuracy: 0.7164\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7184 - val_loss: 0.6039 - val_accuracy: 0.6867\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7133 - val_loss: 0.6078 - val_accuracy: 0.6821\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7078 - val_loss: 0.5788 - val_accuracy: 0.7177\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7086 - val_loss: 0.6164 - val_accuracy: 0.6827\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7179 - val_loss: 0.5791 - val_accuracy: 0.7212\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7151 - val_loss: 0.5740 - val_accuracy: 0.7170\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7199 - val_loss: 0.5770 - val_accuracy: 0.7143\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7192 - val_loss: 0.5850 - val_accuracy: 0.7101\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7128 - val_loss: 0.6323 - val_accuracy: 0.6697\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7098 - val_loss: 0.5909 - val_accuracy: 0.6995\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7191 - val_loss: 0.5929 - val_accuracy: 0.6990\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7141 - val_loss: 0.5765 - val_accuracy: 0.7204\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7159 - val_loss: 0.5832 - val_accuracy: 0.7059\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7249 - val_loss: 0.5742 - val_accuracy: 0.7160\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7110 - val_loss: 0.5788 - val_accuracy: 0.7177\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6969 - val_loss: 0.5721 - val_accuracy: 0.7193\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7265 - val_loss: 0.5840 - val_accuracy: 0.7070\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7139 - val_loss: 0.5957 - val_accuracy: 0.7009\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7139 - val_loss: 0.5907 - val_accuracy: 0.6986\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7186 - val_loss: 0.5713 - val_accuracy: 0.7239\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7195 - val_loss: 0.5855 - val_accuracy: 0.7118\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7179 - val_loss: 0.5841 - val_accuracy: 0.7076\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7147 - val_loss: 0.5709 - val_accuracy: 0.7177\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7228 - val_loss: 0.5815 - val_accuracy: 0.7175\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7224 - val_loss: 0.5700 - val_accuracy: 0.7202\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7047 - val_loss: 0.5749 - val_accuracy: 0.7216\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7025 - val_loss: 0.5881 - val_accuracy: 0.7105\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7061 - val_loss: 0.6341 - val_accuracy: 0.6674\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7074 - val_loss: 0.5799 - val_accuracy: 0.7214\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7212 - val_loss: 0.5717 - val_accuracy: 0.7227\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7242 - val_loss: 0.5863 - val_accuracy: 0.7074\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7146 - val_loss: 0.5787 - val_accuracy: 0.7126\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7139 - val_loss: 0.5798 - val_accuracy: 0.7141\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7183 - val_loss: 0.5697 - val_accuracy: 0.7229\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7220 - val_loss: 0.5692 - val_accuracy: 0.7206\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.7137 - val_loss: 0.5744 - val_accuracy: 0.7237\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7033 - val_loss: 0.6123 - val_accuracy: 0.6842\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7099 - val_loss: 0.5732 - val_accuracy: 0.7216\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7205 - val_loss: 0.5762 - val_accuracy: 0.7141\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7233 - val_loss: 0.5731 - val_accuracy: 0.7160\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7244 - val_loss: 0.5731 - val_accuracy: 0.7212\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7232 - val_loss: 0.5761 - val_accuracy: 0.7175\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7242 - val_loss: 0.5965 - val_accuracy: 0.7026\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7101 - val_loss: 0.6027 - val_accuracy: 0.6842\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7092 - val_loss: 0.5889 - val_accuracy: 0.6982\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7105 - val_loss: 0.5681 - val_accuracy: 0.7250\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7156 - val_loss: 0.5673 - val_accuracy: 0.7233\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7182 - val_loss: 0.5672 - val_accuracy: 0.7231\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7128 - val_loss: 0.5829 - val_accuracy: 0.7082\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7260 - val_loss: 0.5824 - val_accuracy: 0.7091\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7202 - val_loss: 0.5703 - val_accuracy: 0.7179\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7264 - val_loss: 0.5766 - val_accuracy: 0.7193\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7246 - val_loss: 0.5784 - val_accuracy: 0.7110\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7151 - val_loss: 0.5771 - val_accuracy: 0.7193\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7274 - val_loss: 0.5681 - val_accuracy: 0.7187\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7267 - val_loss: 0.5795 - val_accuracy: 0.7116\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7217 - val_loss: 0.5670 - val_accuracy: 0.7258\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7278 - val_loss: 0.5819 - val_accuracy: 0.7164\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7283 - val_loss: 0.5778 - val_accuracy: 0.7120\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7158 - val_loss: 0.5724 - val_accuracy: 0.7231\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7290 - val_loss: 0.5745 - val_accuracy: 0.7227\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7220 - val_loss: 0.5890 - val_accuracy: 0.6999\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7074 - val_loss: 0.5734 - val_accuracy: 0.7191\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7252 - val_loss: 0.5749 - val_accuracy: 0.7168\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7237 - val_loss: 0.5656 - val_accuracy: 0.7210\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7199 - val_loss: 0.5926 - val_accuracy: 0.7049\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7190 - val_loss: 0.5652 - val_accuracy: 0.7239\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7264 - val_loss: 0.5783 - val_accuracy: 0.7193\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7195 - val_loss: 0.5782 - val_accuracy: 0.7210\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7269 - val_loss: 0.5923 - val_accuracy: 0.6990\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7089 - val_loss: 0.5721 - val_accuracy: 0.7195\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7231 - val_loss: 0.5718 - val_accuracy: 0.7164\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7274 - val_loss: 0.5649 - val_accuracy: 0.7183\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7269 - val_loss: 0.5655 - val_accuracy: 0.7250\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7174 - val_loss: 0.6739 - val_accuracy: 0.6486\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6996 - val_loss: 0.6131 - val_accuracy: 0.6842\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7207 - val_loss: 0.5643 - val_accuracy: 0.7269\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7314 - val_loss: 0.5693 - val_accuracy: 0.7262\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7166 - val_loss: 0.5710 - val_accuracy: 0.7187\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7208 - val_loss: 0.5645 - val_accuracy: 0.7223\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7340 - val_loss: 0.5758 - val_accuracy: 0.7244\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7275 - val_loss: 0.5707 - val_accuracy: 0.7189\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7299 - val_loss: 0.5659 - val_accuracy: 0.7265\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7233 - val_loss: 0.5863 - val_accuracy: 0.7049\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7181 - val_loss: 0.5647 - val_accuracy: 0.7221\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7264 - val_loss: 0.5738 - val_accuracy: 0.7168\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7187 - val_loss: 0.5651 - val_accuracy: 0.7265\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7285 - val_loss: 0.5634 - val_accuracy: 0.7248\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7259 - val_loss: 0.5713 - val_accuracy: 0.7252\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7101 - val_loss: 0.6070 - val_accuracy: 0.6925\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7139 - val_loss: 0.5998 - val_accuracy: 0.6894\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7187 - val_loss: 0.5797 - val_accuracy: 0.7129\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7304 - val_loss: 0.5676 - val_accuracy: 0.7208\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7279 - val_loss: 0.5652 - val_accuracy: 0.7237\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7262 - val_loss: 0.5870 - val_accuracy: 0.7105\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7065 - val_loss: 0.5671 - val_accuracy: 0.7237\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7205 - val_loss: 0.5671 - val_accuracy: 0.7210\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7206 - val_loss: 0.5801 - val_accuracy: 0.7105\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7217 - val_loss: 0.5720 - val_accuracy: 0.7187\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7259 - val_loss: 0.6028 - val_accuracy: 0.6959\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7152 - val_loss: 0.5845 - val_accuracy: 0.7116\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7123 - val_loss: 0.5690 - val_accuracy: 0.7193\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7226 - val_loss: 0.5933 - val_accuracy: 0.7053\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7209 - val_loss: 0.5810 - val_accuracy: 0.7091\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7252 - val_loss: 0.5627 - val_accuracy: 0.7279\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7255 - val_loss: 0.5637 - val_accuracy: 0.7275\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7309 - val_loss: 0.5672 - val_accuracy: 0.7258\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7314 - val_loss: 0.5662 - val_accuracy: 0.7248\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7300 - val_loss: 0.5747 - val_accuracy: 0.7214\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7231 - val_loss: 0.5751 - val_accuracy: 0.7149\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7234 - val_loss: 0.5737 - val_accuracy: 0.7162\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7279 - val_loss: 0.5631 - val_accuracy: 0.7271\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7328 - val_loss: 0.5658 - val_accuracy: 0.7231\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7208 - val_loss: 0.5877 - val_accuracy: 0.7097\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7233 - val_loss: 0.5638 - val_accuracy: 0.7219\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7252 - val_loss: 0.6200 - val_accuracy: 0.6848\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7133 - val_loss: 0.5774 - val_accuracy: 0.7147\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7219 - val_loss: 0.5643 - val_accuracy: 0.7204\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7314 - val_loss: 0.5837 - val_accuracy: 0.7154\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7251 - val_loss: 0.5686 - val_accuracy: 0.7216\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7261 - val_loss: 0.5685 - val_accuracy: 0.7229\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6962 - val_loss: 0.5902 - val_accuracy: 0.6915\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7215 - val_loss: 0.5645 - val_accuracy: 0.7285\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7289 - val_loss: 0.5629 - val_accuracy: 0.7267\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7203 - val_loss: 0.5710 - val_accuracy: 0.7185\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7290 - val_loss: 0.5611 - val_accuracy: 0.7250\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7162 - val_loss: 0.5916 - val_accuracy: 0.7062\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7257 - val_loss: 0.5679 - val_accuracy: 0.7231\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7214 - val_loss: 0.6030 - val_accuracy: 0.6969\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7239 - val_loss: 0.5687 - val_accuracy: 0.7271\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7264 - val_loss: 0.5611 - val_accuracy: 0.7256\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7346 - val_loss: 0.5609 - val_accuracy: 0.7250\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7301 - val_loss: 0.5725 - val_accuracy: 0.7183\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7069 - val_loss: 0.5804 - val_accuracy: 0.7068\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7195 - val_loss: 0.5662 - val_accuracy: 0.7202\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7310 - val_loss: 0.5724 - val_accuracy: 0.7168\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7233 - val_loss: 0.5650 - val_accuracy: 0.7214\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7247 - val_loss: 0.5650 - val_accuracy: 0.7208\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7291 - val_loss: 0.5605 - val_accuracy: 0.7294\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7327 - val_loss: 0.5661 - val_accuracy: 0.7250\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7330 - val_loss: 0.5766 - val_accuracy: 0.7172\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7285 - val_loss: 0.5727 - val_accuracy: 0.7235\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7249 - val_loss: 0.5624 - val_accuracy: 0.7296\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7275 - val_loss: 0.6085 - val_accuracy: 0.6938\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7265 - val_loss: 0.5596 - val_accuracy: 0.7306\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7329 - val_loss: 0.5779 - val_accuracy: 0.7221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18633f04790>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train, y_train, validation_data = (x_test, y_test), epochs =500, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "858dafb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 482us/step - loss: 0.5779 - accuracy: 0.7221\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with evaluate() method\n",
    "test_loss, test_acc = ann.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bef4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7221\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the model \n",
    "print('Test accuracy:', round(test_acc,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bf31ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5779\n"
     ]
    }
   ],
   "source": [
    "# Loss of the model \n",
    "print('Test loss:', round(test_loss,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54fa7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be76145d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1944,  458,  870, 1506], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1d2417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.69      0.75      2814\n",
      "        True       0.63      0.77      0.69      1964\n",
      "\n",
      "    accuracy                           0.72      4778\n",
      "   macro avg       0.72      0.73      0.72      4778\n",
      "weighted avg       0.74      0.72      0.72      4778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc532e1",
   "metadata": {},
   "source": [
    "<p style=\"background-color:lightpink;font-family:newtimeroman;font-size:20px;line-height:1.7em;text-align:center;border-radius:5px 5px\">Conclusion</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f979a",
   "metadata": {},
   "source": [
    "1. In this project i got 72% of test accuracy.\n",
    "\n",
    "2. You can improve model accuracy by doing : \n",
    "\n",
    "     a) Treating missing valuse, Outliers\n",
    "     \n",
    "     b) Feature Transformation\n",
    "     \n",
    "     c) Feature Selection\n",
    "     \n",
    "     d) Tuning Hyper parameters in Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7bab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
